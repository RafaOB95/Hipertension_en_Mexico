{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a5deb7-103c-48be-b25c-056539a09e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carga los resultados generales y de MLP\n",
    "df_clasicos = pd.read_csv(\"resultados_todos_escenarios.csv\")\n",
    "df_mlp = pd.read_csv(\"resultados_mlp_todos.csv\")\n",
    "\n",
    "# Unifica los dataframes\n",
    "df_total = pd.concat([df_clasicos, df_mlp], ignore_index=True)\n",
    "\n",
    "# Filtra y agrupa Escenario 1\n",
    "metricas = [\"Accuracy\", \"Recall\", \"Precision\", \"F1-score\", \"Specificity\", \"AUC-ROC\"]\n",
    "df_esc1 = df_total[df_total[\"Escenario\"].str.contains(\"Escenario 1\")]\n",
    "df_esc1 = df_esc1.groupby(\"Modelo\")[metricas].mean().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c92ca4-3f4f-4d2f-b62a-16f8c9fe9eb3",
   "metadata": {},
   "source": [
    "# Escenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b52a421-ed19-46bc-a2cd-ade1b5825b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crear carpeta para guardar las gráficas\n",
    "carpeta = \"graficas_escenario1\"\n",
    "os.makedirs(carpeta, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72d7b9-50f6-4aae-979a-c06c7598a473",
   "metadata": {},
   "source": [
    "## Gráfica 1: Comparación de métricas por modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156fbbf1-0e98-4fad-9aca-e5a134cf349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ya no necesitas esta línea porque df_esc1 ya está en el formato correcto\n",
    "# df_metricas = df_esc1[[\"Modelo\"] + metricas].set_index(\"Modelo\")\n",
    "\n",
    "df_esc1.plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Comparación de métricas por modelo – Escenario 1\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta, \"escenario1_comparacion_metricas_modelos.png\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65be6ef-0103-4ee9-8b27-270f4a92ea00",
   "metadata": {},
   "source": [
    "## Gráfica 2: Tiempo de entrenamiento por modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c58d58-fa66-48c4-843e-b13069799671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el promedio de tiempo por modelo en Escenario 1\n",
    "df_tiempo = df_total[df_total[\"Escenario\"].str.contains(\"Escenario 1\")]\n",
    "df_tiempo = df_tiempo.groupby(\"Modelo\")[\"Tiempo (s)\"].mean()\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(df_tiempo.index, df_tiempo.values, color='gray')\n",
    "plt.title(\"Tiempo de entrenamiento por modelo – Escenario 1\")\n",
    "plt.ylabel(\"Segundos\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta, \"escenario1_tiempo_entrenamiento_modelos.png\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b85708f-7f2e-4fde-90c1-b022428ebee4",
   "metadata": {},
   "source": [
    "## Gráfica 3: Comparación Recall vs Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910ca78b-07bc-4cab-b5c3-94776ad67c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recall_spec = df_esc1[[\"Recall\", \"Specificity\"]]\n",
    "\n",
    "df_recall_spec.plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Recall vs Specificity – Escenario 1\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta, \"escenario1_recall_vs_specificity.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d383b1-83df-4a6e-b2ed-22eb52bac069",
   "metadata": {},
   "source": [
    "# Escenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb42a5cc-7d9d-4cd3-a633-ca3b2ddab556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra solo resultados del Escenario 2\n",
    "df_esc2 = df_total[df_total[\"Escenario\"].str.contains(\"Escenario 2\")]\n",
    "\n",
    "# Agrupa por modelo y calcula promedios de métricas\n",
    "df_esc2 = df_esc2.groupby(\"Modelo\")[metricas].mean().sort_index()\n",
    "\n",
    "# Carpeta de salida\n",
    "carpeta = \"graficas_escenario2\"\n",
    "os.makedirs(carpeta, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5696236-b0ba-4b2e-badc-87589ecaee87",
   "metadata": {},
   "source": [
    "## Gráfica 1 – Comparación de métricas por modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f1b24ad-52a4-4a75-bc7a-26b8bda425f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esc2.plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Comparación de métricas por modelo – Escenario 2\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta, \"escenario2_comparacion_metricas_modelos.png\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900f192-2d39-486a-912b-61c8ed9b1072",
   "metadata": {},
   "source": [
    "## Gráfica 2 – Recall vs Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebed06a3-298f-4072-b938-7098a491fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recall_spec = df_esc2[[\"Recall\", \"Specificity\"]]\n",
    "\n",
    "df_recall_spec.plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Recall vs Specificity – Escenario 2\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta, \"escenario2_recall_vs_specificity.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6540af-26c9-480e-a457-60ec5f32a8ba",
   "metadata": {},
   "source": [
    "## Gráfica 3 – Tiempo de entrenamiento por modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ee6910-c44e-4b57-9ac2-4524289142e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio del tiempo por modelo (se extrae antes de agrupar)\n",
    "df_tiempo_esc2 = df_total[df_total[\"Escenario\"].str.contains(\"Escenario 2\")]\n",
    "df_tiempo_esc2 = df_tiempo_esc2.groupby(\"Modelo\")[\"Tiempo (s)\"].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(df_tiempo_esc2.index, df_tiempo_esc2.values, color='gray')\n",
    "plt.title(\"Tiempo de entrenamiento por modelo – Escenario 2\")\n",
    "plt.ylabel(\"Segundos\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta, \"escenario2_tiempo_entrenamiento_modelos.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b529cbf8-acd9-478e-a932-940fe4198cc3",
   "metadata": {},
   "source": [
    "# Escenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3facce6a-8b66-4340-94b2-41987126178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra y concatena los resultados del Escenario 3\n",
    "df_esc3 = df_total[df_total[\"Escenario\"].str.contains(\"Escenario 3\")].copy()\n",
    "\n",
    "# Agrupa por modelo para obtener métricas promedio\n",
    "metricas = [\"Accuracy\", \"Recall\", \"Precision\", \"F1-score\", \"Specificity\", \"AUC-ROC\"]\n",
    "df_esc3 = df_esc3.groupby(\"Modelo\")[metricas + [\"Tiempo (s)\"]].mean().round(3).sort_index()\n",
    "\n",
    "# Crea carpeta de salida\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "carpeta = \"graficas_escenario3\"\n",
    "os.makedirs(carpeta, exist_ok=True)\n",
    "\n",
    "# Gráfica 1 – Comparación de métricas por modelo\n",
    "df_esc3[metricas].plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Comparación de métricas por modelo – Escenario 3\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta, \"escenario3_comparacion_metricas_modelos.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Gráfica 2 – Recall vs Specificity\n",
    "df_esc3[[\"Recall\", \"Specificity\"]].plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Recall vs Specificity – Escenario 3\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta, \"escenario3_recall_vs_specificity.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Filtrar solo Escenario 3 (evita falsos positivos con espacios o guiones)\n",
    "df_tiempo_esc3 = df_total[df_total[\"Escenario\"].str.strip().str.contains(\"Escenario 3\", case=False, regex=False)]\n",
    "\n",
    "# Agrupar por modelo y sumar tiempos\n",
    "df_tiempo_esc3 = df_tiempo_esc3.groupby(\"Modelo\", as_index=False)[\"Tiempo (s)\"].sum().sort_values(\"Tiempo (s)\", ascending=False)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(df_tiempo_esc3[\"Modelo\"], df_tiempo_esc3[\"Tiempo (s)\"], color='gray')\n",
    "plt.title(\"Tiempo total de entrenamiento por modelo – Escenario 3\")\n",
    "plt.ylabel(\"Segundos\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graficas_escenario3/escenario3_tiempo_total_entrenamiento_modelos.png\")\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924bd81c-3cd1-472f-bc1c-ae38451909b9",
   "metadata": {},
   "source": [
    "# Escenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea6d239e-2f3d-49e8-9f6d-6110f79c1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtra solo resultados del Escenario 4\n",
    "df_esc4 = df_total[df_total[\"Escenario\"].str.contains(\"Escenario 4\")].copy()\n",
    "\n",
    "# Agrupa por modelo y calcula promedios\n",
    "metricas = [\"Accuracy\", \"Recall\", \"Precision\", \"F1-score\", \"Specificity\", \"AUC-ROC\"]\n",
    "df_esc4 = df_esc4.groupby(\"Modelo\")[metricas + [\"Tiempo (s)\"]].mean().round(3).sort_index()\n",
    "\n",
    "# Crear carpeta de salida\n",
    "carpeta_esc4 = \"graficas_escenario4\"\n",
    "os.makedirs(carpeta_esc4, exist_ok=True)\n",
    "\n",
    "# Gráfica 1 – Comparación de métricas por modelo\n",
    "df_esc4[metricas].plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Comparación de métricas por modelo – Escenario 4\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta_esc4, \"escenario4_comparacion_metricas_modelos.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Gráfica 2 – Recall vs Specificity\n",
    "df_esc4[[\"Recall\", \"Specificity\"]].plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Recall vs Specificity – Escenario 4\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(carpeta_esc4, \"escenario4_recall_vs_specificity.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Tiempo total por modelo en Escenario 4\n",
    "df_tiempo_esc4 = df_total[df_total[\"Escenario\"].str.contains(\"Escenario 4\")]\n",
    "df_tiempo_esc4 = df_tiempo_esc4.groupby(\"Modelo\")[\"Tiempo (s)\"].sum()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(df_tiempo_esc4.index, df_tiempo_esc4.values, color='gray')\n",
    "plt.title(\"Tiempo total de entrenamiento por modelo – Escenario 4\")\n",
    "plt.ylabel(\"Segundos\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graficas_escenario4/escenario4_tiempo_total_entrenamiento_modelos.png\")\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f9beb-3ed8-4aed-8a4e-745413a804e1",
   "metadata": {},
   "source": [
    "## Matrices de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b63cbb6-8699-46d2-a426-85801a622dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Crear carpeta de salida\n",
    "carpeta_salida = \"matrices_confusion\"\n",
    "os.makedirs(carpeta_salida, exist_ok=True)\n",
    "\n",
    "# Agrupar por modelo y escenario y sumar las matrices\n",
    "df_confusion = df_total.groupby([\"Modelo\", \"Escenario\"])[[\"TP\", \"FP\", \"FN\", \"TN\"]].sum().reset_index()\n",
    "\n",
    "# Función para graficar matriz\n",
    "def graficar_matriz_confusion(tp, fp, fn, tn, modelo, escenario):\n",
    "    matriz = [[tn, fp],\n",
    "              [fn, tp]]\n",
    "\n",
    "    etiquetas = [\"Negativa\", \"Positiva\"]\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(matriz, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=etiquetas, yticklabels=etiquetas)\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(f\"{modelo} - {escenario}\")\n",
    "    plt.tight_layout()\n",
    "    nombre_archivo = f\"{carpeta_salida}/matriz_{modelo}_{escenario.replace(' ', '_').replace('–','-')}.png\"\n",
    "    plt.savefig(nombre_archivo)\n",
    "    plt.close()\n",
    "\n",
    "# Iterar sobre las combinaciones agrupadas\n",
    "for _, fila in df_confusion.iterrows():\n",
    "    modelo = fila[\"Modelo\"]\n",
    "    escenario = fila[\"Escenario\"]\n",
    "    tp, fp, fn, tn = int(fila[\"TP\"]), int(fila[\"FP\"]), int(fila[\"FN\"]), int(fila[\"TN\"])\n",
    "    graficar_matriz_confusion(tp, fp, fn, tn, modelo, escenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee4ca6-712c-4ab4-92e5-0e01dbedca69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
